{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# `Architecture of ViT: `\n",
    "\n",
    "<br>\n",
    "\n",
    "![image_image](img/img.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "1. **ইনপুট চিত্রের বিভাজন (Image Partitioning):**\n",
    "\n",
    "- Input Picture কে ছোট ছোট প্যাচে `(Patch বলতে, ছবিটা ভাগ করা হয় । আমরা উপরের ছবিতে ইচ্ছে করলে ৪ ভাগে ভাগ করতে পারবো)` বিভক্ত করা হয়। উদাহরণস্বরূপ, একটি  224×224 চিত্রকে 16×16 পিক্সেলের প্যাচে ভাগ করলে, আমরা ছবিতে কে ১৪ টুকরা করতে পারবো 224x224 = 14*(16x16) । \n",
    "\n",
    "- প্রতিটি প্যাচকে Flatten করা হয় এবং একটি ভেক্টরে রূপান্তর করা হয়। আমরা যখন, transformer পড়েছি, তখন, দেখেছি এইটা 1D data input নেয় । \n",
    "\n",
    "2. **প্যাচ এম্বেডিং (Patch Embedding):**\n",
    "\n",
    "- প্রতিটি প্যাচ ভেক্টরের উপর লিনিয়ার প্রজেকশন(Linear Projection) অ্যাপ্লাই করা হয়, যা প্যাচের বৈশিষ্ট্য ধারণ করে।\n",
    "- এরপর প্যাচগুলোর সাথে পজিশন এম্বেডিং যোগ করা হয়। পজিশন এম্বেডিং চিত্রের প্যাচগুলোর ক্রম ধরে রাখার জন্য ব্যবহৃত হয়। `Position Embedding simillar to Positional Encoding in Transformer.`\n",
    "\n",
    "### `এখানে, Linear Projection কী?`\n",
    "\n",
    "আগে আমরা উপরের architecture এর সাথে related আমরা কিছু mathmatical equation দেখি। তারপর Linear Projection সম্পর্কে জানবো । \n",
    "\n",
    "\n",
    "![image](img/img01.png)\n",
    "\n",
    "\n",
    "`উপরের প্রথম equation এ`,\n",
    " \n",
    "- $X_{p}^1$ হচ্ছে ছবির ১ম টুকরা (1st patch) । \n",
    "- $X_{p}^2$ হচ্ছে ছবির ২য় টুকরা (2nd patch) । \n",
    "- $X_{p}^3$ হচ্ছে ছবির ৩য় টুকরা (3rd patch) । \n",
    "\n",
    "**`এখন, Equation এ E কি?`**\n",
    "\n",
    "E হচ্ছে Embedding আর আমরা **Linear Projection** এর মাধ্যমে এই Embedding বানিয়ে থাকি । **Linear Projection** মানে হলো $X_{p1}$ -এর ফ্ল্যাটেন করা ভেক্টরটি একটি **Feed-Forward Neural Network (FFNN)**-এ দেওয়া হয়।  এই FFNN আসলে একটি **Fully Connected Layer**, যেটি $X_{p1}$ -এর ইনপুট ভেক্টরকে প্রজেক্ট করে একটি নির্দিষ্ট ডাইমেনশনের **Embedding Vector**-এ রূপান্তর করে। এই প্রজেকশনের মাধ্যমে $X_{p1}$ -এর **Feature Representation** তৈরি করা হয়, যেটি পরবর্তী ট্রান্সফরমার ব্লকে প্রসেস করা হয়। \n",
    "\n",
    "**`এখানে, [class] কি?`**\n",
    "আমরা তো ছবি কে কয়েক ভাবে ভাগ করে ফেলতেছি । কিন্তু, ছবিটা কীসের ছিল সেইটা তো আমাদের জানা দরকার আর সেই information থাকে আমাদের [class] token এ । \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
