For Hand notes you can check here ЁЯСЙЁЯП╗ [Note](https://drive.google.com/file/d/1jIHPl8kmqQtvLFhD8SZPmSl0FbP_wPiv/view?usp=drive_link)
---
<br>

---

# Back_Propogation:

---

<br>

**Back Propogation:** Is an algorithm to train a neural network.

**What is training of a neural network :** Find out the most accurate value of weights and bias .

![Alt text](img/image-69.png)


<br>

**How we can find the best accureate value of weights and bias:**
<br>
- рж╢рзБрж░рзБрждрзЗ ржЖржорж░рж╛, weights and bias random value ржжрж┐рзЯрзЗ рж╢рзБрж░рзБ ржХрж░рж┐  ржмрж╛ weights=1 and bias=0 ржзрж░рзЗ рж╢рзБрж░рзБ ржХрж░рж┐ ред ржЖржорж░рж╛ ржПржЗржЦрж╛ржирзЗ weights=1 and bias=0  рж╢рзБрж░рзБ ржХрж░ржмрзЛред 

- activation function: **linear** then **forward propogation** to determine the predicted value.

![Alt text](img/image-70.png)

- predicted value  ржЖрж░ actual value difference ржЕржирзЗржХ ржмрзЗрж╢рж┐ ред ржХрж╛рж░ржг, ржЖржорж░рж╛  weights and bias random value ржжрж┐рзЯрзЗ рж╢рзБрж░рзБ ржХрж░рзЗржЫрж┐рж▓рж╛ржо ред рждрж╛ржЗ ржПржЦржи ржЖржорж╛ржжрзЗрж░ рж▓рж╕ ржмрж╛ error ржирж┐рж░рзНржирзЯ ржХрж░рждрзЗ рж╣ржмрзЗ loss function ржжрж┐рзЯ ред 

- loss рж╢рзБржзрзБ ржорж╛рждрзНрж░  predicted value ржПрж░ ржЙржкрж░ ржирж┐рж░рзНржнрж░ ржХрж░рзЗ ржЖржмрж╛рж░ predicted value рж╢рзБржзрзБ ржорж╛рждрзНрж░ weights and bias value ржПрж░ ржЙржкрж░ ржирж┐рж░рзНржнрж░ ржХрж░рзЗред рждрж╛ржЗ ржЖржорж░рж╛ neural network ржкрж┐ржЫржирзЗ ржЧрж┐рзЯрзЗ weight and bias ржПрж░ ржнрзНржпрж╛рж▓рзБ ржЧрзБрж▓рзЛ adjust ржХрж░ржмрзЛ(using gradient decent) ржПржЗржЯрж╛рзЯ рж╣ржЪрзНржЫрзЗ backpopogation of neural network ред 

![Alt text](img/image-71.png)


<br> <br>

ржПржЦржи ржЖржорж░рж╛ Defination ржЯрж╛ ржмрзБржЭржмрзЛ ржнрж╛рж▓рзЛ ржнрж╛ржмрзЗ ред 

![Alt text](img/image-72.png)

<br>

**Output layer, hidden layer  ржПрж░ weight and bias ржорж╛ржи ржХрзАржнрж╛ржмрзЗ ржХрж░рждрзЗ рж╣рзЯ рждрж╛ ржЖржорж░рж╛ ml ржП рж╢рж┐ржЦрзЗржЫрж┐рж▓рж╛ржо ред** 

